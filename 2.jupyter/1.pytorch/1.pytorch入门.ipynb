{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.tensors使用\n",
    "tensor 类似numpy的ndarray，唯一的区别是Tensor可以在GPU上加速运算。\n",
    "文档地址：https://pytorch.org/docs/torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5414e-44, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "#创建空矩阵\n",
    "x = torch.empty(5,3)\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0752, 0.7042, 0.5692, 0.6063],\n",
      "        [0.0103, 0.2387, 0.0026, 0.4889],\n",
      "        [0.3450, 0.0255, 0.8103, 0.1775],\n",
      "        [0.0737, 0.4501, 0.2954, 0.5125]])\n"
     ]
    }
   ],
   "source": [
    "#随机矩阵\n",
    "x = torch.rand(4,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#long型全0矩阵\n",
    "x = torch.zeros(4,4,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "#数组直接构建tensor\n",
    "x = torch.tensor([1.0,2,3,4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从一个已有的tensor构建一个tensor。这些方法会重用原来tensor的特征，例如，数据类型，除非提供新的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.9760,  0.5724,  0.6203],\n",
      "        [-0.2956,  0.3880, -1.7083],\n",
      "        [-0.1816, -0.3425,  1.1022],\n",
      "        [-1.5756,  0.0491, -0.9492]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(4,3,dtype=torch.double) #\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x,dtype=torch.float) #修改类型\n",
    "print(x) #size 跟以前一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到tensor形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1665,  1.2073,  0.6982],\n",
      "        [ 0.0755,  0.8652, -1.1181],\n",
      "        [ 0.1489,  0.3487,  1.3202],\n",
      "        [-0.8148,  0.7755, -0.6853]])\n",
      "tensor([[ 1.1665,  1.2073,  0.6982],\n",
      "        [ 0.0755,  0.8652, -1.1181],\n",
      "        [ 0.1489,  0.3487,  1.3202],\n",
      "        [-0.8148,  0.7755, -0.6853]])\n",
      "tensor([[ 1.1665,  1.2073,  0.6982],\n",
      "        [ 0.0755,  0.8652, -1.1181],\n",
      "        [ 0.1489,  0.3487,  1.3202],\n",
      "        [-0.8148,  0.7755, -0.6853]])\n"
     ]
    }
   ],
   "source": [
    "#加法运算, 两种方式\n",
    "y = torch.rand(4,3)\n",
    "\n",
    "print(x+y)\n",
    "\n",
    "print(torch.add(x,y))\n",
    "\n",
    "#加法：把输出作为变量\n",
    "\n",
    "result = torch.empty(4,3)\n",
    "torch.add(x,y,out= result)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in-place加法:y=x+y,结果返回到y上 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1665,  1.2073,  0.6982],\n",
      "        [ 0.0755,  0.8652, -1.1181],\n",
      "        [ 0.1489,  0.3487,  1.3202],\n",
      "        [-0.8148,  0.7755, -0.6853]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：\n",
    "任何in-place的运算都会以``_``结尾。 举例来说：``x.copy_(y)``, ``x.t_()``, 会改变 ``x``。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各种类似NumPy的indexing都可以在PyTorch tensor上面使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5724,  0.6203],\n",
      "        [ 0.3880, -1.7083]])\n"
     ]
    }
   ],
   "source": [
    "print(x[:2,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing: 如果你希望resize/reshape一个tensor，可以使用torch.view："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(),z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有一个只有一个元素的tensor，使用.item()方法可以把里面的value变成Python数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0489])\n",
      "0.04888658970594406\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###numpy和tensor之间转换\n",
    "\n",
    "Torch Tensor和NumPy array会共享内存，所以改变其中一项也会改变另一项。\n",
    "\n",
    "把Torch Tensor转变成NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(8)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy() #转numpy\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改变numpy array里面的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(2)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把NumPy ndarray转成Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3.]\n",
      "tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,2,out = a)\n",
    "print (a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有CPU上的Tensor都支持转成numpy或者从numpy转成Tensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###CUDA Tensors\n",
    "使用.to方法，Tensor可以被移动到别的device上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x,device=device) #在GPU上创建tensor\n",
    "    \n",
    "    x = x.to(device)  #转到gpu，or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double)) #转成cpu，并改变type\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用numpy实现两层神经网络\n",
    "一个全连接ReLU神经网络，一个隐藏层，没有bias。用来从x预测y，使用L2 Loss。\n",
    "\n",
    "这一实现完全使用numpy来计算前向神经网络，loss，和反向传播。\n",
    "\n",
    "numpy ndarray是一个普通的n维array。它不知道任何关于深度学习或者梯度(gradient)的知识，也不知道计算图(computation graph)，只是一种用来计算数学运算的数据结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 23682262.069874708\n",
      "10 2844937.626818004\n",
      "20 262312.2981393648\n",
      "30 84135.25461929964\n",
      "40 32815.93217014946\n",
      "50 14136.731450632218\n",
      "60 6558.356400944219\n",
      "70 3234.5730572430703\n",
      "80 1681.5777304929707\n",
      "90 915.8213042072607\n",
      "100 518.6571628697882\n",
      "110 302.71803458185946\n",
      "120 180.87878165963372\n",
      "130 110.04122786591489\n",
      "140 67.88573820504426\n",
      "150 42.339343352743015\n",
      "160 26.631030006956045\n",
      "170 16.872118294537508\n",
      "180 10.748390066405733\n",
      "190 6.878742688237029\n",
      "200 4.419273617723595\n",
      "210 2.848639742213871\n",
      "220 1.841573645183747\n",
      "230 1.1935801058040174\n",
      "240 0.7753655156719301\n",
      "250 0.5047252585607946\n",
      "260 0.3291653631447625\n",
      "270 0.21503816356788477\n",
      "280 0.14070238379277689\n",
      "290 0.09219582083955112\n",
      "300 0.06049345366282413\n",
      "310 0.039740955340409466\n",
      "320 0.026138084506863165\n",
      "330 0.017209642978849957\n",
      "340 0.011342294372491568\n",
      "350 0.007482423193660584\n",
      "360 0.004940461327461458\n",
      "370 0.0032647366750481075\n",
      "380 0.0021590559177970276\n",
      "390 0.001428904316704597\n",
      "400 0.000946326849952885\n",
      "410 0.0006271347615142479\n",
      "420 0.0004158597886357795\n",
      "430 0.00027592890141783235\n",
      "440 0.00018318436920365568\n",
      "450 0.00012167727310937909\n",
      "460 8.086472076296357e-05\n",
      "470 5.376761889201537e-05\n",
      "480 3.576749718019426e-05\n",
      "490 2.380424632737496e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N,D_in,H,D_out = 64,1000,100,10\n",
    "\n",
    "#创建随机数据\n",
    "x = np.random.randn(N,D_in)\n",
    "y = np.random.randn(N,D_out)\n",
    "\n",
    "#随机初始化权重 Randomly initialize weights\n",
    "w1 = np.random.randn(D_in,H)\n",
    "w2 = np.random.randn(H,D_out)\n",
    "\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    \n",
    "    #1.前向传播 Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h,0)\n",
    "    y_hat =h_relu.dot(w2)\n",
    "    \n",
    "    #2.计算损失；均方差 compute and print loss\n",
    "    loss = np.square(y_hat - y).sum()\n",
    "    if t %10 ==0:\n",
    "        print(t,loss)\n",
    "    \n",
    "    #3.反向传播\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    \n",
    "    \n",
    "    grad_y_hat =2.0 * (y_hat - y)\n",
    "    \n",
    "    grad_w2 = h_relu.T.dot(grad_y_hat)\n",
    "    grad_h_relu = grad_y_hat.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    #update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###pytorch:tensors 实现两层神经网络\n",
    "\n",
    "我们使用PyTorch tensors来创建前向神经网络，计算损失，以及反向传播。\n",
    "\n",
    "一个PyTorch Tensor很像一个numpy的ndarray。但是它和numpy ndarray最大的区别是，PyTorch Tensor可以在CPU或者GPU上运算。如果想要在GPU上运算，就需要把Tensor换成cuda类型。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "#create random input and output\n",
    "\n",
    "x = torch.randn(N,D_in,device=device,dtype = dtype)\n",
    "y = torch.randn(N,D_out,device = device,dtype = dtype)\n",
    "\n",
    "#randomly initialize weights\n",
    "w1 = torch.randn(D_in,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
